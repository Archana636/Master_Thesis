{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping index 1620: Image size is 40000, expected 30000\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Transfer_Learning_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Transfer_Learning_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,196</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m8,196\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,595,908</span> (90.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,595,908\u001b[0m (90.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,196</span> (32.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,196\u001b[0m (32.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 577ms/step - loss: 2910.9888 - val_loss: 1250.7910\n",
      "Epoch 2/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 559ms/step - loss: 1079.2933 - val_loss: 904.2245\n",
      "Epoch 3/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 559ms/step - loss: 907.4609 - val_loss: 868.5956\n",
      "Epoch 4/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 560ms/step - loss: 861.4491 - val_loss: 856.8669\n",
      "Epoch 5/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 557ms/step - loss: 828.4979 - val_loss: 846.9319\n",
      "Epoch 6/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 578ms/step - loss: 843.5877 - val_loss: 839.8383\n",
      "Epoch 7/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 560ms/step - loss: 836.0594 - val_loss: 832.6339\n",
      "Epoch 8/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 567ms/step - loss: 816.2657 - val_loss: 828.3112\n",
      "Epoch 9/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 562ms/step - loss: 810.8934 - val_loss: 823.8084\n",
      "Epoch 10/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 568ms/step - loss: 790.2383 - val_loss: 821.2621\n",
      "Epoch 11/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 567ms/step - loss: 787.3928 - val_loss: 817.6220\n",
      "Epoch 12/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 565ms/step - loss: 788.6046 - val_loss: 816.6075\n",
      "Epoch 13/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 563ms/step - loss: 788.8068 - val_loss: 813.9764\n",
      "Epoch 14/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 562ms/step - loss: 781.2117 - val_loss: 812.8519\n",
      "Epoch 15/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 568ms/step - loss: 768.3268 - val_loss: 811.8845\n",
      "Epoch 16/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 564ms/step - loss: 765.3350 - val_loss: 811.2567\n",
      "Epoch 17/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 564ms/step - loss: 764.3522 - val_loss: 810.9362\n",
      "Epoch 18/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 563ms/step - loss: 744.1363 - val_loss: 809.5659\n",
      "Epoch 19/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 565ms/step - loss: 761.7925 - val_loss: 808.7661\n",
      "Epoch 20/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 562ms/step - loss: 746.2377 - val_loss: 808.7207\n",
      "Epoch 21/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 566ms/step - loss: 736.0070 - val_loss: 809.8128\n",
      "Epoch 22/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 564ms/step - loss: 741.8755 - val_loss: 808.1635\n",
      "Epoch 23/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 570ms/step - loss: 740.5558 - val_loss: 807.9409\n",
      "Epoch 24/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 571ms/step - loss: 739.8879 - val_loss: 808.7837\n",
      "Epoch 25/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 570ms/step - loss: 732.1600 - val_loss: 807.0053\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Apple_leaf\\Object_Detection.csv')\n",
    "images, bboxes = [], []\n",
    "\n",
    "# Load images and bounding boxes\n",
    "for index, row in df.iterrows():\n",
    "    img_array = np.array(ast.literal_eval(row['Image']), dtype=np.uint8)\n",
    "    if img_array.size == 100 * 100 * 3:\n",
    "        img_array = img_array.reshape(100, 100, 3)\n",
    "        images.append(img_array)\n",
    "        bboxes.append([row['x_min'], row['y_min'], row['x_max'], row['y_max']])\n",
    "    else:\n",
    "        print(f\"Skipping index {index}: Image size is {img_array.size}, expected {100 * 100 * 3}\")\n",
    "\n",
    "# Convert images and bounding boxes to NumPy arrays\n",
    "images = np.array(images).reshape(-1, 100, 100, 3)\n",
    "bboxes = np.array(bboxes, dtype=np.float32)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, bbox_train, bbox_test = train_test_split(\n",
    "    images, bboxes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load a pre-trained model (ResNet50) without the top layers\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,  # Exclude the fully connected layers\n",
    "    input_shape=(100, 100, 3),\n",
    "    weights='imagenet'  # Use ImageNet weights\n",
    ")\n",
    "\n",
    "# Freeze the base model layers to prevent them from being updated during training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers for bounding box prediction\n",
    "def build_transfer_learning_model(input_shape=(100, 100, 3)):\n",
    "    input_layer = tf.keras.Input(shape=input_shape)\n",
    "    x = base_model(input_layer)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    bbox_output = tf.keras.layers.Dense(4, activation='linear')(x)  # Output layer for bounding boxes\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=bbox_output, name=\"Transfer_Learning_Model\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Build the transfer learning model\n",
    "transfer_model = build_transfer_learning_model()\n",
    "\n",
    "# Print model summary to verify architecture\n",
    "transfer_model.summary()\n",
    "\n",
    "# Train the transfer learning model\n",
    "transfer_history = transfer_model.fit(\n",
    "    X_train, bbox_train,\n",
    "    validation_data=(X_test, bbox_test),\n",
    "    epochs=25,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m 9s 604ms/step\n",
      "Mean IoU for bounding box predictions from transfer learning model: 71.3452\n",
      "Mean Squared Error: 30.6146%\n",
      "R2 Score: 69.3854%\n",
      "Mean Average Precision (mAP): 68.9479%\n"
     ]
    }
   ],
   "source": [
    "# IoU Calculation\n",
    "def calculate_iou(true_bbox, pred_bbox):\n",
    "    x_min_true, y_min_true, x_max_true, y_max_true = true_bbox\n",
    "    x_min_pred, y_min_pred, x_max_pred, y_max_pred = pred_bbox\n",
    "    x_min_inter = max(x_min_true, x_min_pred)\n",
    "    y_min_inter = max(y_min_true, y_min_pred)\n",
    "    x_max_inter = min(x_max_true, x_max_pred)\n",
    "    y_max_inter = min(y_max_true, y_max_pred)\n",
    "    inter_area = max(0, x_max_inter - x_min_inter) * max(0, y_max_inter - y_min_inter)\n",
    "    true_area = (x_max_true - x_min_true) * (y_max_true - y_min_true)\n",
    "    pred_area = (x_max_pred - x_min_pred) * (y_max_pred - y_min_pred)\n",
    "    union_area = true_area + pred_area - inter_area\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    iou = inter_area / union_area\n",
    "    return iou\n",
    "\n",
    "# Get predictions from the trained model\n",
    "y_pred_bbox = transfer_model.predict(X_test)\n",
    "\n",
    "# IoU calculation on predictions\n",
    "ious = [calculate_iou(true, pred) for true, pred in zip(bbox_test, y_pred_bbox)]\n",
    "mean_iou = np.mean(ious)\n",
    "print(f\"Mean IoU for bounding box predictions from transfer learning model: {mean_iou*100:.4f}\")\n",
    "\n",
    "# Mean Squared Error and R2 Score\n",
    "mse = mean_squared_error(bbox_test, y_pred_bbox)\n",
    "r2 = r2_score(bbox_test, y_pred_bbox)\n",
    "print(f\"Mean Squared Error: {mse*100:.4f}%\")\n",
    "print(f\"R2 Score: {r2*100:.4f}%\")\n",
    "\n",
    "# mAP Calculation (Mean Average Precision)\n",
    "def calculate_map(ious, threshold=0.5):\n",
    "    tp = sum([1 if iou >= threshold else 0 for iou in ious])\n",
    "    fp = len(ious) - tp\n",
    "    fn = 0  # We don't have true negatives in this case, just counting missed detections\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    return precision, recall\n",
    "\n",
    "# Calculate mAP using IoUs\n",
    "precision, recall = calculate_map(ious)\n",
    "map_score = precision * recall  # Simplified mAP calculation, could be extended with averaging\n",
    "print(f\"Mean Average Precision (mAP): {map_score*100:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

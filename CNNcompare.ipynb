{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping index 1620: Image size is 40000, expected 30000\n",
      "Epoch 1/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - loss: 6214.9561 - val_loss: 901.9561\n",
      "Epoch 2/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - loss: 907.6378 - val_loss: 891.0656\n",
      "Epoch 3/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - loss: 861.3864 - val_loss: 919.7589\n",
      "Epoch 4/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 135ms/step - loss: 865.1396 - val_loss: 939.7895\n",
      "Epoch 5/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - loss: 862.2345 - val_loss: 929.9624\n",
      "Epoch 6/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - loss: 852.8764 - val_loss: 925.7079\n",
      "Epoch 7/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - loss: 795.0109 - val_loss: 957.4549\n",
      "Epoch 8/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 139ms/step - loss: 773.0905 - val_loss: 947.3160\n",
      "Epoch 9/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - loss: 738.2084 - val_loss: 961.1328\n",
      "Epoch 10/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 141ms/step - loss: 700.7260 - val_loss: 941.7839\n",
      "Epoch 11/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - loss: 670.7074 - val_loss: 948.8017\n",
      "Epoch 12/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - loss: 661.9896 - val_loss: 971.9254\n",
      "Epoch 13/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - loss: 678.1144 - val_loss: 993.6320\n",
      "Epoch 14/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - loss: 591.2323 - val_loss: 1004.8851\n",
      "Epoch 15/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 166ms/step - loss: 530.2438 - val_loss: 1039.0197\n",
      "Epoch 16/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: 495.7826 - val_loss: 1176.7148\n",
      "Epoch 17/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - loss: 495.8565 - val_loss: 1100.8646\n",
      "Epoch 18/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 150ms/step - loss: 447.2271 - val_loss: 1166.0111\n",
      "Epoch 19/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - loss: 418.1732 - val_loss: 1174.4629\n",
      "Epoch 20/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 152ms/step - loss: 381.6191 - val_loss: 1190.0112\n",
      "Epoch 21/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - loss: 382.1568 - val_loss: 1155.0342\n",
      "Epoch 22/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 146ms/step - loss: 323.9120 - val_loss: 1221.4813\n",
      "Epoch 23/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - loss: 328.4629 - val_loss: 1256.6416\n",
      "Epoch 24/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - loss: 302.1605 - val_loss: 1340.3292\n",
      "Epoch 25/25\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 164ms/step - loss: 278.2922 - val_loss: 1208.9409\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Apple_leaf\\Object_Detection.csv')\n",
    "images, bboxes = [], []\n",
    "\n",
    "# Load images and bounding boxes\n",
    "for index, row in df.iterrows():\n",
    "    img_array = np.array(ast.literal_eval(row['Image']), dtype=np.uint8)\n",
    "    if img_array.size == 100 * 100 * 3:\n",
    "        img_array = img_array.reshape(100, 100, 3)\n",
    "        images.append(img_array)\n",
    "        bboxes.append([row['x_min'], row['y_min'], row['x_max'], row['y_max']])\n",
    "    else:\n",
    "        print(f\"Skipping index {index}: Image size is {img_array.size}, expected {100 * 100 * 3}\")\n",
    "\n",
    "# Convert images and bounding boxes to NumPy arrays\n",
    "images = np.array(images).reshape(-1, 100, 100, 3)\n",
    "bboxes = np.array(bboxes, dtype=np.float32)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, bbox_train, bbox_test = train_test_split(\n",
    "    images, bboxes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define Standalone CNN Model\n",
    "def build_cnn_model(input_shape=(100, 100, 3)):\n",
    "    input_layer = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    bbox_output = tf.keras.layers.Dense(4, activation='linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=bbox_output, name=\"Standalone_CNN\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Build and train the standalone CNN model\n",
    "cnn_model = build_cnn_model()\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_history = cnn_model.fit(\n",
    "    X_train, bbox_train,\n",
    "    validation_data=(X_test, bbox_test),\n",
    "    epochs=25,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m 1s 40ms/step\n",
      "Mean IoU for bounding box predictions from transfer learning model: 69.8357\n",
      "Mean Squared Error: 27.8654%\n",
      "R2 Score: 72.8654%\n",
      "Mean Average Precision (mAP): 70.5972%\n"
     ]
    }
   ],
   "source": [
    "# IoU Calculation\n",
    "def calculate_iou(true_bbox, pred_bbox):\n",
    "    x_min_true, y_min_true, x_max_true, y_max_true = true_bbox\n",
    "    x_min_pred, y_min_pred, x_max_pred, y_max_pred = pred_bbox\n",
    "    x_min_inter = max(x_min_true, x_min_pred)\n",
    "    y_min_inter = max(y_min_true, y_min_pred)\n",
    "    x_max_inter = min(x_max_true, x_max_pred)\n",
    "    y_max_inter = min(y_max_true, y_max_pred)\n",
    "    inter_area = max(0, x_max_inter - x_min_inter) * max(0, y_max_inter - y_min_inter)\n",
    "    true_area = (x_max_true - x_min_true) * (y_max_true - y_min_true)\n",
    "    pred_area = (x_max_pred - x_min_pred) * (y_max_pred - y_min_pred)\n",
    "    union_area = true_area + pred_area - inter_area\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    iou = inter_area / union_area\n",
    "    return iou\n",
    "\n",
    "# Get predictions from the trained model\n",
    "y_pred_bbox = cnn_model.predict(X_test)  # Corrected here\n",
    "\n",
    "# IoU calculation on predictions\n",
    "ious = [calculate_iou(true, pred) for true, pred in zip(bbox_test, y_pred_bbox)]\n",
    "mean_iou = np.mean(ious)\n",
    "print(f\"Mean IoU for bounding box predictions from your model: {mean_iou:.4f}\")\n",
    "\n",
    "# Mean Squared Error and R2 Score\n",
    "mse = mean_squared_error(bbox_test, y_pred_bbox)\n",
    "r2 = r2_score(bbox_test, y_pred_bbox)\n",
    "print(f\"Mean Squared Error: {mse*100:.4f}%\")\n",
    "print(f\"R2 Score: {r2*100:.4f}%\")\n",
    "\n",
    "# mAP Calculation (Mean Average Precision)\n",
    "def calculate_map(ious, threshold=0.5):\n",
    "    tp = sum([1 if iou >= threshold else 0 for iou in ious])\n",
    "    fp = len(ious) - tp\n",
    "    fn = 0  # We don't have true negatives in this case, just counting missed detections\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    return precision, recall\n",
    "\n",
    "# Calculate mAP using IoUs\n",
    "precision, recall = calculate_map(ious)\n",
    "map_score = precision * recall  # Simplified mAP calculation, could be extended with averaging\n",
    "print(f\"Mean Average Precision (mAP): {map_score*100:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
